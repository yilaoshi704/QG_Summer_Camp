{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-11T02:49:04.965597Z",
     "start_time": "2024-07-11T02:49:04.724339700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,472\n",
      "              ReLU-2         [-1, 64, 112, 112]               0\n",
      "       BatchNorm2d-3         [-1, 64, 112, 112]             128\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,928\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,928\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "    ResidualBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,928\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,928\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "    ResidualBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 28, 28]          73,856\n",
      "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
      "             ReLU-21          [-1, 128, 28, 28]               0\n",
      "           Conv2d-22          [-1, 128, 28, 28]         147,584\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "           Conv2d-24          [-1, 128, 28, 28]           8,320\n",
      "             ReLU-25          [-1, 128, 28, 28]               0\n",
      "    ResidualBlock-26          [-1, 128, 28, 28]               0\n",
      "           Conv2d-27          [-1, 128, 28, 28]         147,584\n",
      "      BatchNorm2d-28          [-1, 128, 28, 28]             256\n",
      "             ReLU-29          [-1, 128, 28, 28]               0\n",
      "           Conv2d-30          [-1, 128, 28, 28]         147,584\n",
      "      BatchNorm2d-31          [-1, 128, 28, 28]             256\n",
      "             ReLU-32          [-1, 128, 28, 28]               0\n",
      "    ResidualBlock-33          [-1, 128, 28, 28]               0\n",
      "           Conv2d-34          [-1, 256, 14, 14]         295,168\n",
      "      BatchNorm2d-35          [-1, 256, 14, 14]             512\n",
      "             ReLU-36          [-1, 256, 14, 14]               0\n",
      "           Conv2d-37          [-1, 256, 14, 14]         590,080\n",
      "      BatchNorm2d-38          [-1, 256, 14, 14]             512\n",
      "           Conv2d-39          [-1, 256, 14, 14]          33,024\n",
      "             ReLU-40          [-1, 256, 14, 14]               0\n",
      "    ResidualBlock-41          [-1, 256, 14, 14]               0\n",
      "           Conv2d-42          [-1, 256, 14, 14]         590,080\n",
      "      BatchNorm2d-43          [-1, 256, 14, 14]             512\n",
      "             ReLU-44          [-1, 256, 14, 14]               0\n",
      "           Conv2d-45          [-1, 256, 14, 14]         590,080\n",
      "      BatchNorm2d-46          [-1, 256, 14, 14]             512\n",
      "             ReLU-47          [-1, 256, 14, 14]               0\n",
      "    ResidualBlock-48          [-1, 256, 14, 14]               0\n",
      "           Conv2d-49            [-1, 512, 7, 7]       1,180,160\n",
      "      BatchNorm2d-50            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-51            [-1, 512, 7, 7]               0\n",
      "           Conv2d-52            [-1, 512, 7, 7]       2,359,808\n",
      "      BatchNorm2d-53            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-54            [-1, 512, 7, 7]         131,584\n",
      "             ReLU-55            [-1, 512, 7, 7]               0\n",
      "    ResidualBlock-56            [-1, 512, 7, 7]               0\n",
      "           Conv2d-57            [-1, 512, 7, 7]       2,359,808\n",
      "      BatchNorm2d-58            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,808\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "    ResidualBlock-63            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-64            [-1, 512, 1, 1]               0\n",
      "          Flatten-65                  [-1, 512]               0\n",
      "           Linear-66                 [-1, 1000]         513,000\n",
      "================================================================\n",
      "Total params: 11,692,520\n",
      "Trainable params: 11,692,520\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 61.46\n",
      "Params size (MB): 44.60\n",
      "Estimated Total Size (MB): 106.63\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_1=False,stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        if use_1:\n",
    "            self.conv3 = nn.Conv2d(in_channels, out_channels, kernel_size=1,stride=stride)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x  # Save the input for the shortcut connection\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        if self.conv3 is not None:\n",
    "            identity = self.conv3(identity)  # Apply the 1x1 convolution to the input\n",
    "        out += identity  # Add the shortcut connection\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_classes=1000):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.b1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.b2 = nn.Sequential(\n",
    "            ResidualBlock(64, 64, use_1=False,stride=1),\n",
    "            ResidualBlock(64, 64, use_1=False,stride=1)\n",
    "        )\n",
    "        self.b3 = nn.Sequential(\n",
    "            ResidualBlock(64, 128, use_1=True,stride=2),\n",
    "            ResidualBlock(128, 128, use_1=False,stride=1)\n",
    "        )\n",
    "        self.b4 = nn.Sequential(\n",
    "            ResidualBlock(128, 256, use_1=True,stride=2),\n",
    "            ResidualBlock(256, 256, use_1=False,stride=1)\n",
    "        )\n",
    "        self.b5 = nn.Sequential(\n",
    "            ResidualBlock(256, 512, use_1=True,stride=2),\n",
    "            ResidualBlock(512, 512, use_1=False,stride=1)\n",
    "        )\n",
    "        self.b6 = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.b1(x)\n",
    "        x = self.b2(x)\n",
    "        x = self.b3(x)\n",
    "        x = self.b4(x)\n",
    "        x = self.b5(x)\n",
    "        x = self.b6(x)\n",
    "        return x\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = ResNet(ResidualBlock).to(device)\n",
    "    print(summary(model, (3, 224, 224)))"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b075f93c031e4664"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
